{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Mgg9QN9uNrcw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtorch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing pytorch\n",
    "\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EZ8e3zr7NeYk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "o5Vnb_oUNeYw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  5   6   7   8\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "torch.Size([3, 4])\n",
      "3\n",
      "\n",
      "  6   7\n",
      " 10  11\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, '<- slicing support')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем тензор\n",
    "x = torch.rand([3, 4])\n",
    "x = torch.zeros([3, 4])\n",
    "x = torch.ones([3, 4, 3])\n",
    "\n",
    "#print(x)\n",
    "#x = torch.eye(3, 4)\n",
    "#print(x)\n",
    "\n",
    "x = torch.Tensor(\n",
    "[[1,  2,  3,  4],\n",
    " [5,  6,  7,  8],\n",
    " [9, 10, 11, 12]])\n",
    "\n",
    "print(x), '<- tensor'\n",
    "print(x.size()), '<- tensor size'\n",
    "print(x.size(0)), '<- dimension size'\n",
    "print(x[1:, 1:3]), '<- slicing support'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DbCTLPtvNeY8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- shallow copy\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "  1   2   3   4\n",
      "  2   2   2   2\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- deep copy\n"
     ]
    }
   ],
   "source": [
    "# Копирование (по ссылке и глубокое)\n",
    "y = x\n",
    "\n",
    "y[1, :] = 1\n",
    "print(x, y, '<- shallow copy')\n",
    "\n",
    "y = x.clone()\n",
    "y[1, :] = 2\n",
    "print(x, y, '<- deep copy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VgNpPXj4NeZG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2   4   6   8\n",
      "  3   3   3   3\n",
      " 18  20  22  24\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "   1    4    9   16\n",
      "   2    2    2    2\n",
      "  81  100  121  144\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 1.0000  1.0000  1.0000  1.0000\n",
      " 0.5000  0.5000  0.5000  0.5000\n",
      " 1.0000  1.0000  1.0000  1.0000\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 0  0  0  0\n",
      "-1 -1 -1 -1\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0  0  0  0\n",
      " 1  1  1  1\n",
      " 0  0  0  0\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      "   1    4    9   16\n",
      "   1    1    1    1\n",
      "  81  100  121  144\n",
      "[torch.FloatTensor of size 3x4]\n",
      " \n",
      " 1.0000e+00  4.0000e+00  2.7000e+01  2.5600e+02\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      " 3.8742e+08  1.0000e+10  2.8531e+11  8.9161e+12\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- basic math\n"
     ]
    }
   ],
   "source": [
    "# Математические операции (стандартные поэлементные)\n",
    "print(x + y, x * y, x / y, x - y,)\n",
    "print(x % y, x**2, x**y, '<- basic math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K5pbUjv8NeZO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2.7183e+00  7.3891e+00  2.0086e+01  5.4598e+01\n",
      " 2.7183e+00  2.7183e+00  2.7183e+00  2.7183e+00\n",
      " 8.1031e+03  2.2026e+04  5.9874e+04  1.6275e+05\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.0000  0.6931  1.0986  1.3863\n",
      " 0.0000  0.0000  0.0000  0.0000\n",
      " 2.1972  2.3026  2.3979  2.4849\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.8415  0.9093  0.1411 -0.7568\n",
      " 0.8415  0.8415  0.8415  0.8415\n",
      " 0.4121 -0.5440 -1.0000 -0.5366\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0.7311  0.8808  0.9526  0.9820\n",
      " 0.7311  0.7311  0.7311  0.7311\n",
      " 0.9999  1.0000  1.0000  1.0000\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Более сложные операции\n",
    "print(torch.exp(x))\n",
    "print(torch.log(x))\n",
    "print(torch.sin(x))\n",
    "print(torch.sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AnNzy-MxNeZU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  4\n",
      "  9\n",
      " 10\n",
      " 11\n",
      " 12\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      " 0  0  0  1\n",
      " 0  0  0  0\n",
      " 1  1  1  1\n",
      "[torch.ByteTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Логические операции\n",
    "y = x[x > 3]\n",
    "print(y)\n",
    "print(x)\n",
    "y = (x > 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fgqhmp6UNeZe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.DoubleTensor of size 3x4]\n",
      "\n",
      "\n",
      "  1   2   3   4\n",
      "  1   1   1   1\n",
      "  9  10  11  12\n",
      "[torch.IntTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Переопределение типа\n",
    "x = x.float()\n",
    "print(x)\n",
    "x = x.double()\n",
    "print(x)\n",
    "x = x.int()\n",
    "print(x)\n",
    "x = x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GVsLJi13NeZm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n",
      "\n",
      " 1  2  3  4\n",
      " 4  3  2  1\n",
      "[torch.LongTensor of size 2x4]\n",
      "\n",
      "[[1 2 3 4]\n",
      " [4 3 2 1]]\n",
      "\n",
      " 1  2  3  4\n",
      " 4  3  2  1\n",
      "[torch.DoubleTensor of size 2x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Взаимодействие с Numpy\n",
    "x = numpy.array([[1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(x)\n",
    "x = torch.from_numpy(x)\n",
    "print(x)\n",
    "x = x.numpy()\n",
    "print(x)\n",
    "x = torch.from_numpy(x).float().int().double()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "V-Qyd7h-NeZ0"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e648a1c93fe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Перемещение на GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<- CUDA Tensor!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_new\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_TensorBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_StorageBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mbe\u001b[0m \u001b[0muntil\u001b[0m \u001b[0mthis\u001b[0m \u001b[0minitialization\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mOrdinary\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mshould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mall\u001b[0m \u001b[0mof\u001b[0m \u001b[0mPyTorch\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mautomatically\u001b[0m \u001b[0minitialize\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mstate\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdemand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mDoes\u001b[0m \u001b[0mnothing\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Перемещение на GPU\n",
    "import time\n",
    "x_cuda = x.cuda()\n",
    "print(x_cuda, '<- CUDA Tensor!')\n",
    "print(x)\n",
    "start = time.time()\n",
    "y = (x - x + x*10.0) ** 2\n",
    "print(time.time() - start, '<- CPU time')\n",
    "start = time.time()\n",
    "y_cuda = (x_cuda - x_cuda + x_cuda * 10.0) ** 2\n",
    "print(time.time() - start, '<- GPU time')\n",
    "y = y_cuda.cpu()\n",
    "print(y)\n",
    "print(x ** 2, '<- operation performed on the GPU!!!')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "L80oyFQ_NeZ-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1   2   3   4\n",
      "  5   6   7   8\n",
      "  9  10  11  12\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "Variable containing:\n",
      "  2   4   6   8\n",
      " 10  12  14  16\n",
      " 18  20  22  24\n",
      "[torch.FloatTensor of size 3x4]\n",
      " <- gradient\n"
     ]
    }
   ],
   "source": [
    "# Автоматическое (символьное) дифференциирование (обратное распространение градиента) (случай скаляра)\n",
    "import torch.autograd\n",
    "\n",
    "x = torch.Tensor(\n",
    "[[1,  2,  3,  4],\n",
    " [5,  6,  7,  8],\n",
    " [9, 10, 11, 12]])\n",
    "\n",
    "print(x)\n",
    "x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "formula = (x_var ** 2).sum().median()\n",
    "formula.backward()\n",
    "\n",
    "print(x_var.grad, '<- gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UWy0KMQmNeaI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 7.3891e+00  5.4598e+01  4.0343e+02  2.9810e+03\n",
      " 2.2026e+04  1.6275e+05  1.2026e+06  8.8861e+06\n",
      " 6.5660e+07  4.8517e+08  3.5849e+09  2.6489e+10\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "Variable containing:\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "Variable containing:\n",
      " 1.4778e+01  1.0920e+02  8.0686e+02  5.9619e+03\n",
      " 4.4053e+04  3.2551e+05  2.4052e+06  1.7772e+07\n",
      " 1.3132e+08  9.7033e+08  7.1698e+09  5.2978e+10\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Автоматическое дифференциирование (обратное распространение градиента) (случай тензора)\n",
    "# variable -> formula1 (вектор) -> formula2 (скаляр)\n",
    "x_var = torch.autograd.Variable(x, requires_grad=True)\n",
    "formula1 = torch.exp(x_var) ** 2.0\n",
    "y_var = torch.autograd.Variable(formula1.data.clone(), requires_grad=True)\n",
    "formula2 = y_var.sum()\n",
    "formula2.backward()\n",
    "y_grad = y_var.grad.clone()\n",
    "print(formula1)\n",
    "print(y_grad)\n",
    "formula1.backward(gradient=y_grad.data)\n",
    "print(x_var.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJbqzdRhNeaQ"
   },
   "source": [
    "## Задание 1\n",
    "Написать и вычислить бинарную кросс-энтопию для векторов target и probs при помощи средств pytorch.\n",
    "Бинарная кросс-энтропия вычисляется:\n",
    "\n",
    "$$BCE(t, p) = - \\sum_i t_i \\log(p_i) + (1 - t_i) \\log(1 - p_i)$$\n",
    "\n",
    "target = (0, 0, 0, 0, 1, 1, 1, 1)\n",
    "probs = (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8)\n",
    "\n",
    "Какой из элементов суммы дает наибольший вклад в функцию потерь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chq6fQNqNebu"
   },
   "source": [
    "# Задание 2\n",
    "\n",
    "Логистическая регрессия минимизирует функцию бинарной кросс-энтропии (BCE), предполагая, что\n",
    "$$p_i = \\sigma (< w_i, x_i >)$$\n",
    "где $w_i$ -- веса свойств объектов, $x_i$ -- свойства объектов. Пусть $\\vec{x} = (1, x_1, x_2)$. Подставить вероятности в выражение $BCE$ и найти производную $BCE$ по весам.\n",
    "Вычислить производную в случае двух объектов (любым способом, можно посчитать руками, можно написать скрипт):\n",
    "\n",
    "$t = 1, x = (1, 1, 1)$\n",
    "\n",
    "$t = 0, x = (1, 0, 1)$\n",
    "\n",
    "В точке w = (0, 0, 0).\n",
    "\n",
    "Совпадает ли результат явного вычисления с результатом работы функции backward?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAwbtKryNecQ"
   },
   "source": [
    "## Задание 3\n",
    "\n",
    "Средствами pytorch реализовать алгоритм градиентного спуска.\n",
    "\n",
    "При помощи этого алгоритма найти минимум функций:\n",
    "$x^2 + y^2$ с начальным приближением $x_0 = 10, y_0 = 5$, \n",
    "\n",
    "$0.5 \\log x + 0.5 \\log (1 - x)$ с начальным приближением $x_0 = 0.9$, \n",
    "\n",
    "$x^2 + 10 y^2 + 2xy$, с начальным приближением $x_0 = 10.0, y_0 = 10.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCBYeVGiNeck"
   },
   "source": [
    "## Задание 4\n",
    "\n",
    "\n",
    "При помощи алгоритма градиентного спуска оптимизировать вектор probs при фиксированном векторе target из задания 1.\n",
    "Рассмотреть два варианта решения задачи: \n",
    "\n",
    "1) при помощи CPU \n",
    "\n",
    "2) при помощи GPU\n",
    "\n",
    "Получилось ли ускорить процесс при помощи GPU? Обсудить, почему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-bGEhOENec6"
   },
   "source": [
    "О градиентном спуске:\n",
    "https://ru.wikipedia.org/wiki/%D0%93%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Lesson_1_Basics.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
